{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"train.json/train.json\", \"r\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b.) Tell us about the data...\n",
    "How many samples (dishes) are there in the training set? How many\n",
    "categories (types of cuisine)? Use a list to keep all the unique ingredients appearing in the\n",
    "training set. How many unique ingredients are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39774 dishes in the dataset.\n",
      "There are 6714 unique types of ingredients in the dataset.\n",
      "There are 20 types of cuisine in the dataset.\n"
     ]
    }
   ],
   "source": [
    "cuisineTypes = set()\n",
    "uniqueIngredients = set()\n",
    "for recipe in data:\n",
    "    cuisineTypes.add(recipe['cuisine'])\n",
    "    ingredients = set(recipe['ingredients'])\n",
    "    uniqueIngredients = uniqueIngredients.union(ingredients)\n",
    "         \n",
    "print(\"There are \" + str(len(data)) + \" dishes in the dataset.\")\n",
    "print(\"There are\", len(uniqueIngredients), \"unique types of ingredients in the dataset.\")        \n",
    "print(\"There are\", len(cuisineTypes), \"types of cuisine in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# d.)\n",
    "Represent each dish by a binary ingredient feature vector. Suppose there are d different ingredients\n",
    "in total from the training set, represent each dish by a 1×d binary ingredient vector\n",
    "x, where xi = 1 if the dish contains ingredient i and xi = 0 otherwise. For example, suppose\n",
    "all the ingredients we have in the training set are { beef, chicken, egg, lettuce, tomato, rice }\n",
    "and the dish is made by ingredients { chicken, lettuce, tomato, rice }, then the dish could be\n",
    "represented by a 6×1 binary vector [0, 1, 0, 1, 1, 1] as its feature or attribute. Use n ×d feature\n",
    "matrix to represent all the dishes in training set and test set, where n is the number of dishes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only run the following cells on your machine once to generate feature_mat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueIngredients = list(uniqueIngredients)\n",
    "\n",
    "def vectorform(recipe):\n",
    "    return np.in1d(uniqueIngredients, recipe['ingredients'], assume_unique = True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated feature matrix of shape: (39774, 6714)\n"
     ]
    }
   ],
   "source": [
    "feature_mat_train = np.array(list(map(vectorform, data)))\n",
    "\n",
    "print(\"Generated feature matrix of shape:\", feature_mat_train.shape)\n",
    "\n",
    "with open('feature_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(feature_mat_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated feature matrix of shape: (9944, 6714)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"test.json/test.json\", \"r\")\n",
    "data_test = json.load(f)\n",
    "\n",
    "feature_mat_test = np.array(list(map(vectorform, data_test)))\n",
    "\n",
    "print(\"Generated feature matrix of shape:\", feature_mat_test.shape)\n",
    "\n",
    "with open('feature_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(feature_mat_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the following cell to load feature mats without regenerating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature matrices of shapes: (39774, 6714) (9944, 6714)\n"
     ]
    }
   ],
   "source": [
    "feature_mat_train = pickle.load(open('feature_train.pickle', 'rb'))\n",
    "feature_mat_test = pickle.load(open('feature_test.pickle', 'rb'))\n",
    "print(\"Loaded feature matrices of shapes:\", feature_mat_train.shape, feature_mat_test.shape)\n",
    "train_expected = np.array([recipe['cuisine'] for recipe in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e.)\n",
    "Using Naïve Bayes Classifier to perform 3 fold cross-validation on the training set and report\n",
    "your average classification accuracy. Try both Gaussian distribution prior assumption and\n",
    "Bernoulli distribution prior assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37925055  0.38185384  0.377377  ] 0.379493793821\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, feature_mat_train, train_expected)\n",
    "print(scores, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68302797  0.68225356  0.68548144] 0.683587657646\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "scores = cross_val_score(bnb, feature_mat_train, train_expected)\n",
    "print(scores, np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Naïve Bayes Gaussian prior avg classification accuracy: 0.3795  \n",
    "Naïve Bayes Bernoulli prior avg classification accuracy: 0.6836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e.) \n",
    "For Gaussian prior and Bernoulli prior, which performs better in terms of cross-validation\n",
    "accuracy? Why? Please give specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f.)\n",
    "Using Logistic Regression Model to perform 3 fold cross-validation on the training set and\n",
    "report your average classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.774787    0.77366317  0.77882584] 0.775758670409\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(penalty='l2', multi_class='ovr')\n",
    "scores = cross_val_score(logreg, feature_mat_train, train_expected)\n",
    "print(scores, np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression avg accuracy: 0.7756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g.) \n",
    "Train your best-performed classifier with all of the training data, and generate test labels on\n",
    "test set. Submit your results to Kaggle and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(penalty='l2', multi_class='ovr')\n",
    "logreg.fit(np.asarray(feature_mat_train), train_expected)\n",
    "result = logreg.predict(feature_mat_test)\n",
    "\n",
    "f = open(\"test.json/test.json\", \"r\")\n",
    "data_test = json.load(f)\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write(\"id,cuisine\\n\")\n",
    "    for label in range(len(result)):\n",
    "        f.write(str(data_test[label]['id']) + \",\" + result[label] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Kaggle Submission](kaggle_score.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The submitted file was renamed to submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
